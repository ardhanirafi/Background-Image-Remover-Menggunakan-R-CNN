{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "import numpy as np\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_masks(mask, threshold=0.5):\n",
    "    \"\"\"Refine the masks based on threshold and remove small regions.\"\"\"\n",
    "    mask = mask > threshold\n",
    "    mask = mask.float()\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_mask, true_mask):\n",
    "    \"\"\"Calculate accuracy, precision, recall, F1-score, TP, FP, TN, FN.\"\"\"\n",
    "    pred_mask_flat = pred_mask.view(-1)\n",
    "    true_mask_flat = true_mask.view(-1)\n",
    "\n",
    "    tp = (pred_mask_flat * true_mask_flat).sum().item()  # True Positives\n",
    "    fp = (pred_mask_flat * (1 - true_mask_flat)).sum().item()  # False Positives\n",
    "    tn = ((1 - pred_mask_flat) * (1 - true_mask_flat)).sum().item()  # True Negatives\n",
    "    fn = ((1 - pred_mask_flat) * true_mask_flat).sum().item()  # False Negatives\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1_score, tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background_advanced(image):\n",
    "    \"\"\"Remove background from the uploaded image using Mask R-CNN.\"\"\"\n",
    "    original_image = Image.fromarray(image).convert(\"RGB\")\n",
    "    \n",
    "    # Define the transformation\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Resize((1024, 1024))  # Increasing the resolution for better accuracy\n",
    "    ])\n",
    "    image_tensor = transform(original_image)\n",
    "\n",
    "    # Load the pre-trained Mask R-CNN model\n",
    "    model = maskrcnn_resnet50_fpn(weights='DEFAULT')  # Update to use weights parameter\n",
    "    model.eval()\n",
    "\n",
    "    # Move image to the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        prediction = model([image_tensor])\n",
    "\n",
    "    # Extract the most confident mask\n",
    "    scores = prediction[0]['scores']\n",
    "    masks = prediction[0]['masks']\n",
    "    highest_score_index = scores.argmax()\n",
    "    mask = masks[highest_score_index, 0]\n",
    "\n",
    "    # Refine the mask\n",
    "    mask = refine_masks(mask, threshold=0.8)  # Adjust threshold for better results\n",
    "\n",
    "    # Apply the refined mask to the image\n",
    "    masked_image = image_tensor * mask\n",
    "\n",
    "    # Convert the tensor back to an image\n",
    "    final_image = T.ToPILImage()(masked_image.cpu()).convert(\"RGB\")\n",
    "    original_image = original_image.resize((1024, 1024))  # Resize for consistency\n",
    "    mask_image = T.ToPILImage()(mask.cpu()).convert(\"L\")  # Convert mask to grayscale\n",
    "\n",
    "    # Simulate a true mask for demonstration purposes (this should be replaced with actual ground truth)\n",
    "    true_mask = torch.zeros_like(mask)  # Replace with actual true mask if available\n",
    "    true_mask[mask > 0] = 1  # Assuming the object is present in the mask\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy, precision, recall, f1_score, tp, fp, tn, fn = calculate_metrics(mask.cpu(), true_mask.cpu())\n",
    "    \n",
    "    # Print metrics to the console\n",
    "    print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1_score:.2f}\")\n",
    "    print(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "\n",
    "    return final_image, original_image, mask_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradio_interface(image):\n",
    "    \"\"\"Gradio interface function to process the uploaded image.\"\"\"\n",
    "    final_image, original_image, mask_image = remove_background_advanced(image)\n",
    "    return final_image, original_image, mask_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Image(type=\"numpy\"),  # Single input for the image\n",
    "    outputs=[gr.Image(type=\"pil\"), gr.Image(type=\"pil\"), gr.Image(type=\"pil\")],  # Remove metric outputs\n",
    "    title=\"Background Removal with Mask R-CNN\",\n",
    "    description=\"Upload an image to remove its background using Mask R-CNN. The process includes the original image and the mask.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "TP: 163889.0, FP: 0.0, TN: 884687.0, FN: 0.0\n",
      "Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "TP: 380798.0, FP: 0.0, TN: 667778.0, FN: 0.0\n",
      "Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "TP: 343161.0, FP: 0.0, TN: 705415.0, FN: 0.0\n",
      "Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "TP: 612375.0, FP: 0.0, TN: 436201.0, FN: 0.0\n",
      "Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "TP: 173848.0, FP: 0.0, TN: 874728.0, FN: 0.0\n",
      "Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1-Score: 1.00\n",
      "TP: 175362.0, FP: 0.0, TN: 873214.0, FN: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Launch the interface\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
